# This project implements an end-to-end tech stack for a data platform
follow Data Lake-House architecture, there are main interfaces of this platform: 
- Distributed query/execution engine: Spark Thrift Server
- Stream processing: Kafka
- Storage: HDFS
- Data mart: ClickHouse
- Orchestration: Airflow
- Main file format: Parquet with Snappy compression
- Warehouse table format: Hive and Iceberg

### How-to-run will be uploaded later