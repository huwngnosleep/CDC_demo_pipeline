version: '3.7'

services:
  # spark-apps:
  #   user: root
  #   image: spark:latest
  #   container_name: spark-apps
  #   volumes:
  #     - ./config/spark:${SPARK_HOME}/conf/:ro
  #     - ./code:${SPARK_HOME}/code:ro
  #     - spark_home:/home/spark:rw
  #   command: "${SPARK_HOME}/bin/spark-submit 
  #     --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \ 
  #     --master spark://spark-master:7077 \
  #     --executor-cores 4 \
  #     --executor-memory 8G \
  #     ${SPARK_HOME}/code/process.py"

# $SPARK_HOME/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 --master spark://spark-master:7077 $SPARK_HOME/code/process.py

  spark-master:
    # root user to avoid permission deny in $SPARK_HOME, need improving later
    user: root
    image: spark:latest
    container_name: spark-master
    ports:
      - "${SPARK_MASTER_WEB_UI_PORT}:8080"
      - "${SPARK_MASTER_PORT}:7077"
    restart: always
    volumes:
      - ./code:${SPARK_HOME}/code:ro
      - ./config/spark/spark-thriftserver.properties:${SPARK_HOME}/conf/spark-thriftserver.properties:ro
      - ./config/spark/hive-site.xml:${SPARK_HOME}/conf/hive-site.xml
    healthcheck:
      test: ["CMD", "curl", "-s", "http://localhost:8080/"]
      interval: 1s
      timeout: 10s
      retries: 5
    command: bash -c "
      ${SPARK_HOME}/sbin/start-master.sh \
      && tail -f"

  spark-thriftserver:
    image: spark:latest
    container_name: spark-thriftserver
    ports:
      - "${SPARK_THRIFT_WEB_UI_PORT}:4040"
      - "${SPARK_THRIFT_TCP_PORT}:10000"
    depends_on:
      spark-master:
        condition: service_healthy
    restart: always
    volumes:
      - ./.env:${SPARK_HOME}/.env:ro
      - ./scripts/start_sparkthrift.sh:${SPARK_HOME}/start_sparkthrift.sh
      - ./config/spark/spark-thriftserver.properties:${SPARK_HOME}/conf/spark-thriftserver.properties:ro
      - ./config/spark/hive-site.xml:${SPARK_HOME}/conf/hive-site.xml
    entrypoint: ${SPARK_HOME}/start_sparkthrift.sh

  metastore-mysql:
    image: mysql:5.7
    command: --default-authentication-plugin=mysql_native_password
    container_name: metastore-mysql
    hostname: metastore-mysql
    ports:
      - "3307:3306"
    environment:
      MYSQL_ROOT_PASSWORD: root
    healthcheck:
      test: ["CMD", "mysqladmin" ,"ping", "--password=root"]
      interval: 1s
      timeout: 10s
      retries: 5
    volumes:
      - hive_metastore_mysql:/var/lib/mysql
    restart: always

  metastore:
    user: root
    image: apache/hive:3.1.3
    container_name: metastore
    hostname: metastore
    depends_on:
      metastore-mysql:
        condition: service_healthy
    # ports:
    #   - "9083:9083"
    environment:
      - DB_DRIVER=mysql
      - HADOOP_HOME=/opt/hadoop
    volumes:
      - ./config/spark/hive-site.xml:/opt/hive/conf/hive-site.xml
      - ./jars/mysql-connector-java-8.0.17.jar:/opt/hive/lib/mysql-connector-java-8.0.17.jar
    restart: always

  spark-worker-1:
    image: spark:latest
    container_name: spark-worker-1
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    volumes:
      - ./config/spark/hive-site.xml:${SPARK_HOME}/conf/hive-site.xml
    command: bash -c "${SPARK_HOME}/sbin/start-worker.sh -m ${SPARK_WORKER_MEM} -c ${SPARK_WORKER_CORES} spark://spark-master:7077 && tail -f"
    restart: always

  spark-worker-2:
    image: spark:latest
    container_name: spark-worker-2
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    volumes:
      - ./config/spark/hive-site.xml:${SPARK_HOME}/conf/hive-site.xml
    command: bash -c "${SPARK_HOME}/sbin/start-worker.sh -m ${SPARK_WORKER_MEM} -c ${SPARK_WORKER_CORES} spark://spark-master:7077 && tail -f"
    restart: always

  
volumes:
  spark_home:
  hive_metastore_mysql: