version: '3.7'

services:
  spark-master:
    image: spark:latest
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./config/docker-compose/spark:${SPARK_HOME}/conf/:ro
    command: bash -c "
      ${SPARK_HOME}/sbin/start-master.sh \\
      && tail -f"

  spark-thriftserver:
    image: spark:latest
    container_name: spark-thriftserver
    ports:
      - "4040:4040"
      - "10000:10000"
    depends_on: [spark-master]
    volumes:
      - ./config/docker-compose/spark:${SPARK_HOME}/conf/:ro
    command: bash -c " 
      ${SPARK_HOME}/sbin/start-thriftserver.sh --master spark://spark-master:7077 \
      --deploy-mode client \
      --num-executors 16 \
      --executor-cores 1 \
      --executor-memory 1G \
      --conf spark.cores.max=16 \
      --files ${SPARK_HOME}/conf/hive-site.xml
      && tail -f"

  spark-worker-1:
    image: spark:latest
    container_name: spark-worker-1
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    volumes:
      - ./config/docker-compose/spark:${SPARK_HOME}/conf/:ro
    command: bash -c "${SPARK_HOME}/sbin/start-worker.sh spark://spark-master:7077 && tail -f"

  spark-worker-2:
    image: spark:latest
    container_name: spark-worker-2
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    volumes: 
      - ./config/docker-compose/spark:${SPARK_HOME}/conf/:ro
    command: bash -c "${SPARK_HOME}/sbin/start-worker.sh spark://spark-master:7077 && tail -f"

  
