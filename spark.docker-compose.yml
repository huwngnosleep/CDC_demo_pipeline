version: '3.7'

services:
  spark-master:
    image: spark:latest
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./config/docker-compose/spark:${SPARK_HOME}/conf/:ro
      - ./code:${SPARK_HOME}/code:ro
      - spark_home:/home/spark
    command: bash -c "
      ${SPARK_HOME}/sbin/start-master.sh \\
      && tail -f"

  spark-thriftserver:
    image: spark:latest
    container_name: spark-thriftserver
    ports:
      - "4040:4040"
      - "10000:10000"
    depends_on: [spark-master]
    volumes:
      - ./config/docker-compose/spark:${SPARK_HOME}/conf/:ro
    command: bash -c " 
      ${SPARK_HOME}/sbin/start-thriftserver.sh --master spark://spark-master:7077 \
      --deploy-mode cluster \
      --num-executors 2 \
      --executor-cores 4 \
      --executor-memory 4G \
      --files ${SPARK_HOME}/conf/hive-site.xml
      && tail -f"

  spark-worker-1:
    image: spark:latest
    container_name: spark-worker-1
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    volumes:
      - ./config/docker-compose/spark:${SPARK_HOME}/conf/:ro
    command: bash -c "${SPARK_HOME}/sbin/start-worker.sh -m ${SPARK_WORKER_MEM} -c ${SPARK_WORKER_CORES} spark://spark-master:7077 && tail -f"

  spark-worker-2:
    image: spark:latest
    container_name: spark-worker-2
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    volumes: 
      - ./config/docker-compose/spark:${SPARK_HOME}/conf/:ro
    command: bash -c "${SPARK_HOME}/sbin/start-worker.sh -m ${SPARK_WORKER_MEM} -c ${SPARK_WORKER_CORES} spark://spark-master:7077 && tail -f"

  
volumes:
  spark_home: